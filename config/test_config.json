{
    "clients": {
        "default": "openai_api",
        "temperature": 0.0,
        "ollama": {
            "url": "http://localhost:11434",
            "model": "llama3.2-vision"
        },
        "openai_api": {
            "api_key": "sk-48e5e88388384e06938acb67198b655a",
            "model": "qwen-vl-max",
            "api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
        }
    },
    "prompt_dir": "prompts",
    "prompts": [
        {
            "name": "Frame Analysis",
            "path": "frame_analysis/frame_analysis.txt"
        },
        {
            "name": "Video Reconstruction",
            "path": "frame_analysis/describe.txt"
        },
        {
            "name": "Frame Screening",
            "path": "frame_analysis/frame_screening.txt"
        }
    ],
    "output_dir": "output",
    "frames": {
        "per_minute": 10,
        "analysis_threshold": 10.0,
        "min_difference": 5.0,
        "max_count": 30,
        "start_stage": 1,
        "max_frames": 20
    },
    "response_length": {
        "frame": 300,
        "reconstruction": 1000,
        "narrative": 500
    },
    "audio": {
        "whisper_model": "medium",
        "sample_rate": 16000,
        "channels": 1,
        "quality_threshold": 0.2,
        "chunk_length": 30,
        "language_confidence_threshold": 0.8,
        "language": "zh",
        "device": "cpu"
    },
    "keep_frames": true,
    "prompt": "",
    "two_stage_analysis": {
        "enabled": true,
        "small_model": {
            "client": "ollama",
            "model": "llama3.2-vision",
            "importance_threshold": 6,
            "max_frames_for_deep_analysis": 5
        },
        "large_model": {
            "client": "openai_api",
            "model": "qwen-vl-max"
        }
    }
}






